{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc21980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9435894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'c:\\Users\\ice\\projects\\iris')\n",
    "\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from iris.utils.data_utils import display_product_summary\n",
    "from iris.config.data_pipeline_config_manager import DataPipelineConfigManager\n",
    "from iris.config.embedding_pipeline_config_manager import EmbeddingPipelineConfigManager\n",
    "from iris.data_pipeline.mongodb_manager import MongoDBManager\n",
    "from iris.embedding_pipeline.embedding_handler import EmbeddingHandler\n",
    "from iris.embedding_pipeline.embedding_database import EmbeddingDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration managers\n",
    "data_config = DataPipelineConfigManager()\n",
    "embedding_config = EmbeddingPipelineConfigManager()\n",
    "\n",
    "shop_config = data_config.shop_config\n",
    "mongodb_config = data_config.mongodb_config\n",
    "\n",
    "# Create MongoDB manager\n",
    "mongodb_manager = MongoDBManager(mongodb_config)\n",
    "\n",
    "# Initialize the EmbeddingHandler and Database\n",
    "embedding_handler = EmbeddingHandler(embedding_config.clip_config)\n",
    "embedding_db = EmbeddingDatabase(embedding_config.database_config, shop_config)\n",
    "embedding_db.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cursor to list since it can only be iterated once\n",
    "image_dataset = list(mongodb_manager.get_collection(\n",
    "    mongodb_manager.mongodb_config.image_metadata_collection\n",
    ").find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the query hash's index and embedding\n",
    "query_hash = '3068271dd98042007498c8ee1a4604dc'\n",
    "\n",
    "# Find index of the query hash in the database\n",
    "hash_index = embedding_db.ids.index(query_hash)\n",
    "query_embedding = embedding_db.embeddings[hash_index]\n",
    "\n",
    "# Search for nearest neighbors\n",
    "results = embedding_db.search(query_embedding, k=50)\n",
    "print(\"Nearest neighbors for query hash\", query_hash, \":\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash_source(hash_val):\n",
    "    \"\"\"Get source data for a hash (either image path or localization data)\"\"\"\n",
    "    # First check if it's a regular image hash\n",
    "    for data in image_dataset:\n",
    "        if data['hash'] == hash_val:\n",
    "            return {'type': 'image', 'image_data': data}\n",
    "        # Then check if it's a localization hash\n",
    "        if 'localizations' in data:\n",
    "            for localization in data['localizations']:\n",
    "                if localization['hash'] == hash_val:\n",
    "                    return {'type': 'localization', 'localization_data': localization, 'parent_image': data}\n",
    "    return None\n",
    "\n",
    "def get_image_html(source, size=(100, 140)):\n",
    "    \"\"\"Create HTML img tag for either an image path or localization data\"\"\"\n",
    "    if source['type'] == 'image':\n",
    "        image_data = source['image_data']\n",
    "        with Image.open(image_data['local_path']) as img:\n",
    "            img.thumbnail(size)\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format='JPEG', quality=70)\n",
    "            img_b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            return f'<img src=\"data:image/jpeg;base64,{img_b64}\" style=\"max-width:none\">'\n",
    "    else:  # localization\n",
    "        localization_data = source['localization_data']\n",
    "        parent_data = source['parent_image']\n",
    "        \n",
    "        # Get bounding box from original image\n",
    "        with Image.open(parent_data['local_path']) as img:\n",
    "            # Convert relative bbox coordinates to absolute pixels\n",
    "            width, height = img.size\n",
    "            bbox = localization_data['bbox']  # [x, y, width, height] in relative coords\n",
    "            abs_bbox = [\n",
    "                int(bbox[0] * width),      # x\n",
    "                int(bbox[1] * height),     # y\n",
    "                int(bbox[2] * width),      # width\n",
    "                int(bbox[3] * height)      # height\n",
    "            ]\n",
    "            bbox_img = img.crop((\n",
    "                abs_bbox[0],\n",
    "                abs_bbox[1], \n",
    "                abs_bbox[0] + abs_bbox[2], \n",
    "                abs_bbox[1] + abs_bbox[3]\n",
    "            ))\n",
    "            bbox_img.thumbnail(size)\n",
    "            \n",
    "            buffered = BytesIO()\n",
    "            bbox_img.save(buffered, format='JPEG', quality=70)\n",
    "            img_b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            return f'<img src=\"data:image/jpeg;base64,{img_b64}\" style=\"max-width:none\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def find_distance_cutoff(distances, window=7, poly=2, base_std_multiplier=2.0, min_points=5):\n",
    "    \"\"\"Find cutoff point where distances start deviating significantly from the local trend.\n",
    "\n",
    "    Args:\n",
    "        distances: List of distances from nearest neighbor search\n",
    "        window: Window size for smoothing (must be odd)\n",
    "        poly: Polynomial order for smoothing\n",
    "        base_std_multiplier: How many standard deviations to use for threshold\n",
    "        min_points: Minimum number of points to return\n",
    "\n",
    "    Returns:\n",
    "        index: Cutoff index\n",
    "    \"\"\"\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    # First smooth the distances to reduce noise\n",
    "    smoothed = savgol_filter(distances, window, poly)\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    rolling_mean = [np.mean(smoothed[max(0, i-window):i+1]) \n",
    "                   for i in range(len(smoothed))]\n",
    "    rolling_std = [np.std(smoothed[max(0, i-window):i+1])\n",
    "                  for i in range(len(smoothed))]\n",
    "    \n",
    "    # Get baseline statistics from first few points\n",
    "    base_mean = np.mean(smoothed[:min_points])\n",
    "    base_std = np.std(smoothed[:min_points])\n",
    "    \n",
    "    # Find where distance exceeds mean + std threshold\n",
    "    threshold = base_mean + (base_std * base_std_multiplier)\n",
    "\n",
    "    # Look for consistent deviation\n",
    "    cutoff_candidates = []\n",
    "    for i in range(min_points, len(smoothed)):\n",
    "        # Check if point and next few points exceed threshold\n",
    "        if (smoothed[i] > threshold and\n",
    "            smoothed[i] > rolling_mean[i] + rolling_std[i] * base_std_multiplier):\n",
    "            cutoff_candidates.append(i)\n",
    "            if len(cutoff_candidates) >= 3:  # Require multiple points above threshold\n",
    "                return cutoff_candidates[0]\n",
    "    \n",
    "    # If no clear cutoff found, return minimum valid size\n",
    "    return min_points\n",
    "\n",
    "# Get distances from your results\n",
    "distances = [dist for _, dist in results]\n",
    "cutoff_idx = find_distance_cutoff(distances)\n",
    "\n",
    "# Plot results\n",
    "print(f\"Suggested cutoff at index {cutoff_idx} (distance: {distances[cutoff_idx]:.4f})\")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Original distances\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(len(distances))),\n",
    "    y=distances,\n",
    "    name='Distances',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Add smoothed trace\n",
    "smoothed = savgol_filter(distances, 7, 2)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(len(smoothed))),\n",
    "    y=smoothed,\n",
    "    name='Smoothed',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "# Highlight cutoff\n",
    "fig.add_vline(\n",
    "    x=cutoff_idx,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\",\n",
    "    annotation_text=f\"Cutoff at {cutoff_idx}\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distance Distribution with Cutoff',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Distance',\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Show all images, with cutoff ones in red\n",
    "html = ['<div style=\"display: flex; flex-wrap: wrap; gap: 10px;\">']\n",
    "\n",
    "for i, (hash_val, dist) in enumerate(results):\n",
    "    source = get_hash_source(hash_val)\n",
    "    if source is None:\n",
    "        continue\n",
    "\n",
    "    img_html = get_image_html(source)\n",
    "    # Add red text and ❌ for items after cutoff\n",
    "    text_color = 'color: red;' if i >= cutoff_idx else ''\n",
    "    cutoff_marker = '❌ ' if i >= cutoff_idx else ''\n",
    "    item_html = f\"\"\"\n",
    "    <div style='text-align: center; border: 1px solid #ddd; padding: 5px;'>\n",
    "        {img_html}\n",
    "        <br>\n",
    "        <small style='{text_color}'>{cutoff_marker}Index: {i}</small><br>\n",
    "        <small style='{text_color}'>Distance: {dist:.4f}</small><br>\n",
    "        <small style='{text_color}'>Hash: {hash_val}</small>\n",
    "        <small style='{text_color}'>{'(Localization)' if source['type'] == 'localization' else ''}</small>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    html.append(item_html)\n",
    "\n",
    "html.append('</div>')\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Get product scores using weighted distances for all images\n",
    "scores = {}\n",
    "product_titles = {}  # Store product titles for reference\n",
    "title_counts = {}    # Track duplicate titles\n",
    "\n",
    "# Get product collection reference\n",
    "product_collection = mongodb_manager.get_collection(mongodb_manager.mongodb_config.product_collection)\n",
    "\n",
    "# First get the source product of the query image\n",
    "query_source = get_hash_source(query_hash)\n",
    "query_product_hash = query_source['parent_image']['source_product'] if query_source['type'] == 'localization' else query_source['image_data']['source_product']\n",
    "\n",
    "# Skip first result (index 0) since it's the query image itself\n",
    "for (hash_val, dist) in results[1:]:\n",
    "    source = get_hash_source(hash_val)\n",
    "    if source is None:\n",
    "        continue\n",
    "\n",
    "    # Get product ID from parent image\n",
    "    if source['type'] == 'localization':\n",
    "        product_hash = source['parent_image']['source_product']\n",
    "    else:\n",
    "        product_hash = source['image_data']['source_product']\n",
    "\n",
    "    # Get product title if not already stored\n",
    "    if product_hash not in product_titles:\n",
    "        product = product_collection.find_one({'hash': product_hash})\n",
    "        title = product['title'] if product else 'Unknown Product'\n",
    "        # Track duplicate titles\n",
    "        title_counts[title] = title_counts.get(title, 0) + 1\n",
    "        # Add hash suffix for duplicates\n",
    "        if title_counts[title] > 1:\n",
    "            title = f\"{title} ({product_hash[:6]}...)\"\n",
    "        product_titles[product_hash] = title\n",
    "\n",
    "    # Use inverse distance as weight (add small epsilon to avoid division by zero)\n",
    "    weight = 1.0 / (dist + 1e-6)\n",
    "    scores[product_hash] = scores.get(product_hash, 0.0) + weight\n",
    "\n",
    "# Sort products by score\n",
    "sorted_products = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create bar colors array - highlight original product\n",
    "colors = ['red' if hash_val == query_product_hash else 'lightblue' \n",
    "         for hash_val, _ in sorted_products]\n",
    "\n",
    "# Create vertical bar chart of product scores using titles\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        y=[score for _, score in sorted_products],\n",
    "        x=[product_titles[hash_val][:40] + ('...' if len(product_titles[hash_val])>40 else '') for hash_val, _ in sorted_products],\n",
    "        text=[f'{score:.2f}' for _, score in sorted_products],\n",
    "        textposition='auto',\n",
    "        marker_color=colors\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Product Relevance Scores (Red = Query Product)',\n",
    "    yaxis_title='Score',\n",
    "    xaxis_title='Product Title',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    "    xaxis=dict(\n",
    "        tickangle=45,  # Angle the labels for better readability\n",
    "        showgrid=True\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"Related products (in order of relevance):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Display top product using plot_product_summary\n",
    "if sorted_products:\n",
    "    top_product_hash = sorted_products[0][0]\n",
    "    print(f\"Top Product: {product_titles[top_product_hash]} (Score: {sorted_products[0][1]:.2f})\")\n",
    "    display_product_summary(mongodb_manager, top_product_hash)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caeee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update MongoDB with localization point and product hash\n",
    "# Get the parent image hash from query source\n",
    "parent_image_hash = query_source['parent_image']['hash']\n",
    "\n",
    "# Sort predictions by score and create ordered dict\n",
    "product_predictions = {\n",
    "    product_hash: float(score)  # Convert numpy float32 to Python float\n",
    "    for product_hash, score in sorted_products\n",
    "}\n",
    "\n",
    "# Get the point coordinates from the query source\n",
    "bbox = query_source['localization_data']['bbox']\n",
    "point_coords = (\n",
    "    bbox[0] + bbox[2] / 2,  # x coordinate (center of the bounding box)\n",
    "    bbox[1] + bbox[3] / 2   # y coordinate (center of the bounding box)\n",
    ")\n",
    "\n",
    "# Prepare the update for the localization in the image document\n",
    "filter_query = {\n",
    "    'hash': parent_image_hash,\n",
    "    'localizations.hash': query_source['localization_data']['hash']\n",
    "}\n",
    "\n",
    "# Create the update data\n",
    "update_data = {\n",
    "    'localizations.$.localization_point': {\n",
    "        'x': float(point_coords[0]),\n",
    "        'y': float(point_coords[1])\n",
    "    },\n",
    "    'localizations.$.hash': top_product_hash,\n",
    "    'localizations.$.product_predictions': product_predictions\n",
    "}\n",
    "\n",
    "# Update the document\n",
    "success = mongodb_manager.update_one(\n",
    "    mongodb_manager.mongodb_config.image_metadata_collection,\n",
    "    filter_query,\n",
    "    update_data,\n",
    "    upsert=False\n",
    ")\n",
    "\n",
    "print(f\"Database update {'successful' if success else 'failed'}\")\n",
    "\n",
    "# Verify the update by retrieving the document\n",
    "updated_doc = mongodb_manager.find_one(\n",
    "    mongodb_manager.mongodb_config.image_metadata_collection,\n",
    "    {'image': parent_image_hash}\n",
    ")\n",
    "\n",
    "if updated_doc:\n",
    "    for localization in updated_doc['localizations']:\n",
    "        if localization['hash'] == query_source['localization_data']['hash']:\n",
    "            print(\"\\nUpdated localization data:\")\n",
    "            print(f\"Localization hash: {localization['hash']}\")\n",
    "            print(f\"Point coordinates: {localization.get('localization_point', 'Not set')}\")\n",
    "            print(\"\\nTop 5 product predictions:\")\n",
    "            for i, (prod_hash, score) in enumerate(localization.get('product_predictions', {}).items()):\n",
    "                if i >= 5: break\n",
    "                title = product_titles.get(prod_hash, 'Unknown Product')\n",
    "                print(f\"{title}: {score:.2f}\")\n",
    "else:\n",
    "    print(\"Could not retrieve updated document\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
